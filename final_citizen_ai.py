# -*- coding: utf-8 -*-
"""FINAL Citizen AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_eezRly3OES-qa9wdfvW5IeLmfZAVEaD
"""

!pip install transformers torch gradio -q

import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# ---------------------------
# Load Model
# ---------------------------
model_name = "ibm-granite/granite-3.2-2b-instruct"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
    device_map="auto" if torch.cuda.is_available() else None
)

if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token


def generate_response(prompt, max_length=1024):
    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
    if torch.cuda.is_available():
        inputs = {k: v.to(model.device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_length=max_length,
            temperature=0.7,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id
        )

    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    response = response.replace(prompt, "").strip()
    return response


# ---------------------------
# App Functions
# ---------------------------
def city_analysis(city_name):
    prompt = f"Provide a detailed analysis of {city_name} including:\n1. Crime Index and safety statistics\n2. Accident rates and traffic safety information\n3. Overall safety assessment\n\nCity: {city_name}\nAnalysis:"
    return generate_response(prompt, max_length=1000)


def citizen_interaction(query):
    prompt = f"As a government assistant, provide accurate and helpful information about the following citizen query related to public services, government policies, or civic issues:\n\nQuery: {query}\nResponse:"
    return generate_response(prompt, max_length=1000)


def assistant_chat(message, history):
    history = history or []
    response = generate_response(message, max_length=500)
    history.append((message, response))
    return history, history


def collect_feedback(name, rating, comments):
    return f"‚úÖ Thank you {name}! Your feedback has been recorded.\n\nRating: {rating}\nComments: {comments}"


# ---------------------------
# Login System
# ---------------------------
VALID_USERS = {
    "citizen": "ai123",
    "admin": "admin123",
    "guest": "guest123"
}

def login(username, password):
    if username in VALID_USERS and VALID_USERS[username] == password:
        return gr.update(visible=False), gr.update(visible=True), f"‚úÖ Welcome {username}!"
    else:
        return gr.update(visible=True), gr.update(visible=False), "‚ùå Invalid Username or Password"


# ---------------------------
# Build Gradio UI
# ---------------------------
with gr.Blocks() as app:
    gr.Markdown("# üåê Citizen AI Platform")

    # Login Page
    with gr.Group(visible=True) as login_group:
        gr.Markdown("### üîë Login to Continue")
        username = gr.Textbox(label="Username")
        password = gr.Textbox(label="Password", type="password")
        login_btn = gr.Button("Login")
        login_msg = gr.Markdown("")

    # Main App (Initially Hidden)
    with gr.Group(visible=False) as main_group:
        with gr.Tabs():
            # Tab 1: City Analysis
            with gr.TabItem("City Analysis"):
                with gr.Row():
                    city_input = gr.Textbox(label="Enter City Name")
                    analyze_btn = gr.Button("Analyze City")
                city_output = gr.Textbox(label="City Analysis", lines=15)
                analyze_btn.click(city_analysis, inputs=city_input, outputs=city_output)

            # Tab 2: Citizen Services
            with gr.TabItem("Citizen Services"):
                citizen_query = gr.Textbox(
                    label="Your Query",
                    placeholder="Ask about public services, government policies, civic issues...",
                    lines=4
                )
                query_btn = gr.Button("Get Information")
                citizen_output = gr.Textbox(label="Government Response", lines=15)
                query_btn.click(citizen_interaction, inputs=citizen_query, outputs=citizen_output)

            # Tab 3: Assistant
            with gr.TabItem("AI Assistant"):
                gr.Markdown("### ü§ñ Chat with Assistant")
                chatbot = gr.Chatbot()
                msg = gr.Textbox(placeholder="Type your message here...")
                clear = gr.Button("Clear Chat")
                msg.submit(assistant_chat, [msg, chatbot], [chatbot, chatbot])
                clear.click(lambda: None, None, chatbot, queue=False)

            # Tab 4: Feedback
            with gr.TabItem("Feedback"):
                gr.Markdown("### üìù Share Your Feedback")
                name = gr.Textbox(label="Your Name")
                rating = gr.Radio(["Excellent", "Good", "Average", "Poor"], label="Rate Us")
                comments = gr.Textbox(label="Comments", lines=4, placeholder="Enter your suggestions or issues here...")
                submit_btn = gr.Button("Submit Feedback")
                feedback_output = gr.Textbox(label="Response", interactive=False)
                submit_btn.click(collect_feedback, inputs=[name, rating, comments], outputs=feedback_output)

    # Connect login
    login_btn.click(login, inputs=[username, password],
                    outputs=[login_group, main_group, login_msg])


# Launch app
app.launch(share=True)